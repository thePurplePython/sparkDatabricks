{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Parallelization of Machine Learning Algorithms in Apache Spark\n",
    "\n",
    "#### Spark Summit Bay Area Meet Up https://www.youtube.com/watch?v=3p81IYQWB_E\n",
    "\n",
    "#### ML Pipeline Techiques:\n",
    "1. Parallelize Featurization and Single Machine Training\n",
    "2. Parallelize Featurization and Distributed Training\n",
    "3. Many Models Orchestration - One Model Per Executor\n",
    "4. Offline Distributed Training - Online Streaming Predictions\n",
    "5. Offline Single Machine Training - Online Streaming Predictions (**in work**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank-full.csv  bank-names.txt bank.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    ".option(\"path\", \"./bank/bank-full.csv\")\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".option(\"delimiter\", \";\")\\\n",
    ".option(\"quote\", '\"')\\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").saveAsTable(\"bank_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(age=58, job='management', marital='married', education='tertiary', default='no', balance=2143, housing='yes', loan='no', contact='unknown', day=5, month='may', duration=261, campaign=1, pdays=-1, previous=0, poutcome='unknown', y='no')\n",
      "Row(age=44, job='technician', marital='single', education='secondary', default='no', balance=29, housing='yes', loan='no', contact='unknown', day=5, month='may', duration=151, campaign=1, pdays=-1, previous=0, poutcome='unknown', y='no')\n",
      "Row(age=33, job='entrepreneur', marital='married', education='secondary', default='no', balance=2, housing='yes', loan='yes', contact='unknown', day=5, month='may', duration=76, campaign=1, pdays=-1, previous=0, poutcome='unknown', y='no')\n",
      "Row(age=47, job='blue-collar', marital='married', education='unknown', default='no', balance=1506, housing='yes', loan='no', contact='unknown', day=5, month='may', duration=92, campaign=1, pdays=-1, previous=0, poutcome='unknown', y='no')\n",
      "Row(age=33, job='unknown', marital='single', education='unknown', default='no', balance=1, housing='no', loan='no', contact='unknown', day=5, month='may', duration=198, campaign=1, pdays=-1, previous=0, poutcome='unknown', y='no')\n"
     ]
    }
   ],
   "source": [
    "for i in spark.sql(\"select * from bank_sql\").take(5): print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Parallelize Featurization and Single Machine Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = spark.table(\"bank_sql\")\n",
    "cols = input_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "job\n",
      "marital\n",
      "education\n",
      "default\n",
      "balance\n",
      "housing\n",
      "loan\n",
      "contact\n",
      "day\n",
      "month\n",
      "duration\n",
      "campaign\n",
      "pdays\n",
      "previous\n",
      "poutcome\n",
      "y\n"
     ]
    }
   ],
   "source": [
    "for i in cols: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, StringIndexerModel, VectorAssembler\n",
    "\n",
    "catCols = [\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"poutcome\"]\n",
    "stages = [] # pipeline stages\n",
    "for i in catCols:\n",
    "    si = StringIndexer(inputCol=i, outputCol=i+\"Index\") # category indexing\n",
    "    ohe = OneHotEncoder(inputCol=i+\"Index\", outputCol=i+\"classVec\") # binary sparse vectors\n",
    "    stages += [si, ohe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCols = [\"age\", \"balance\", \"campaign\", \"previous\", \"day\"]\n",
    "\n",
    "assemblerInputs = numCols + list(map(lambda x: x + \"classVec\", catCols)) # concat cols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol=\"y\", outputCol=\"label\")\n",
    "stages += [labelIndexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StringIndexer_a747fbdba374\n",
      "OneHotEncoder_407614407687\n",
      "StringIndexer_da21f2ed6bda\n",
      "OneHotEncoder_297d7c7fff7b\n",
      "StringIndexer_2fc172f6283a\n",
      "OneHotEncoder_d05a34a5146d\n",
      "StringIndexer_76781474a422\n",
      "OneHotEncoder_971cd94c7afa\n",
      "StringIndexer_6520c13ab587\n",
      "OneHotEncoder_0e88c5503f01\n",
      "StringIndexer_847ea6b5f9d5\n",
      "OneHotEncoder_c4113294fd37\n",
      "StringIndexer_def962708378\n",
      "OneHotEncoder_cd7709e39ec2\n",
      "StringIndexer_b554d29c23d1\n",
      "OneHotEncoder_98d7623b943c\n",
      "StringIndexer_3d4fd88347c3\n",
      "OneHotEncoder_9c3460b9c82b\n",
      "VectorAssembler_37cf592fb013\n",
      "StringIndexer_74a243b9e088\n"
     ]
    }
   ],
   "source": [
    "for i in stages: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(label=0.0, features=SparseVector(40, {0: 58.0, 1: 2143.0, 2: 1.0, 4: 5.0, 6: 1.0, 16: 1.0, 19: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 25: 1.0, 26: 1.0, 37: 1.0}), age=58, job='management', marital='married', education='tertiary', default='no', balance=2143, housing='yes', loan='no', contact='unknown', day=5, month='may', duration=261, campaign=1, pdays=-1, previous=0, poutcome='unknown', y='no')\n",
      "Row(label=0.0, features=SparseVector(40, {0: 44.0, 1: 29.0, 2: 1.0, 4: 5.0, 7: 1.0, 17: 1.0, 18: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 25: 1.0, 26: 1.0, 37: 1.0}), age=44, job='technician', marital='single', education='secondary', default='no', balance=29, housing='yes', loan='no', contact='unknown', day=5, month='may', duration=151, campaign=1, pdays=-1, previous=0, poutcome='unknown', y='no')\n",
      "Row(label=0.0, features=SparseVector(40, {0: 33.0, 1: 2.0, 2: 1.0, 4: 5.0, 12: 1.0, 16: 1.0, 18: 1.0, 21: 1.0, 22: 1.0, 25: 1.0, 26: 1.0, 37: 1.0}), age=33, job='entrepreneur', marital='married', education='secondary', default='no', balance=2, housing='yes', loan='yes', contact='unknown', day=5, month='may', duration=76, campaign=1, pdays=-1, previous=0, poutcome='unknown', y='no')\n",
      "Row(label=0.0, features=SparseVector(40, {0: 47.0, 1: 1506.0, 2: 1.0, 4: 5.0, 5: 1.0, 16: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 25: 1.0, 26: 1.0, 37: 1.0}), age=47, job='blue-collar', marital='married', education='unknown', default='no', balance=1506, housing='yes', loan='no', contact='unknown', day=5, month='may', duration=92, campaign=1, pdays=-1, previous=0, poutcome='unknown', y='no')\n",
      "Row(label=0.0, features=SparseVector(40, {0: 33.0, 1: 1.0, 2: 1.0, 4: 5.0, 17: 1.0, 21: 1.0, 23: 1.0, 25: 1.0, 26: 1.0, 37: 1.0}), age=33, job='unknown', marital='single', education='unknown', default='no', balance=1, housing='no', loan='no', contact='unknown', day=5, month='may', duration=198, campaign=1, pdays=-1, previous=0, poutcome='unknown', y='no')\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(input_data)\n",
    "dataset = pipelineModel.transform(input_data)\n",
    "\n",
    "selectCols = [\"label\", \"features\"] + cols\n",
    "dataset = dataset.select(selectCols)\n",
    "for i in dataset.take(5): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainData, testData) = dataset.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _**pulls processing all back to driver**_\n",
    "- _**one spark job hence one machine via sklearn**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pandasDF = trainData.select(\"features\", \"label\").toPandas()\n",
    "series = pandasDF[\"features\"].apply(lambda x: np.array(x.toArray())).values.reshape(-1, 1)\n",
    "X = np.apply_along_axis(lambda x: x[0], 1, series)\n",
    "y = np.array(pandasDF[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36249, 40)\n",
      "(36249,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.900e+01, 7.510e+02, 1.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         0.000e+00],\n",
       "        [5.200e+01, 7.180e+03, 1.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         0.000e+00],\n",
       "        [5.400e+01, 1.777e+03, 5.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "         0.000e+00],\n",
       "        ...,\n",
       "        [5.100e+01, 0.000e+00, 2.000e+00, ..., 1.000e+00, 0.000e+00,\n",
       "         0.000e+00],\n",
       "        [8.400e+01, 0.000e+00, 2.000e+00, ..., 1.000e+00, 0.000e+00,\n",
       "         0.000e+00],\n",
       "        [4.100e+01, 0.000e+00, 3.000e+00, ..., 1.000e+00, 0.000e+00,\n",
       "         0.000e+00]]), array([0., 0., 0., ..., 1., 1., 1.])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[X, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "skLr = LogisticRegression(max_iter=1000, tol=0.000001, solver=\"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=1e-06,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skLrModel = skLr.fit(X, y)\n",
    "skLrModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandasTestDF = testData.select(\"features\", \"label\").toPandas()\n",
    "seriesTest = pandasTestDF[\"features\"].apply(lambda x: np.array(x.toArray())).values.reshape(-1,1)\n",
    "xTest = np.apply_along_axis(lambda x: x[0], 1, seriesTest)\n",
    "yTest = np.array(pandasTestDF[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8906494086141487"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skLrModel.score(xTest, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Parallelize Featurization and Distributed Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"label\",\n",
    "                            featuresCol=\"features\",\n",
    "                            maxDepth=10,\n",
    "                            numTrees=20,\n",
    "                            featureSubsetStrategy=\"all\",\n",
    "                            seed=123,\n",
    "                            maxBins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = ParamGridBuilder().addGrid(rf.numTrees, [30, 40, 50]).build()\n",
    "cv = CrossValidator(estimator=rf,\n",
    "                    estimatorParamMaps=pg,\n",
    "                    numFolds=3,\n",
    "                    seed=123,\n",
    "                    parallelism=4,\n",
    "                    evaluator=BinaryClassificationEvaluator())\n",
    "\n",
    "rfModel = cv.fit(trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _**multiple spark jobs being distributed across machines via spark core engine**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(label=0.0, features=SparseVector(40, {0: 33.0, 1: 1905.0, 2: 1.0, 3: 2.0, 4: 13.0, 5: 1.0, 16: 1.0, 18: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 24: 1.0, 26: 1.0}), age=33, job='blue-collar', marital='married', education='secondary', default='no', balance=1905, housing='yes', loan='no', contact='cellular', day=13, month='may', duration=39, campaign=1, pdays=301, previous=2, poutcome='success', y='no', rawPrediction=DenseVector([31.7504, 18.2496]), probability=DenseVector([0.635, 0.365]), prediction=0.0)\n",
      "Row(label=0.0, features=SparseVector(40, {0: 45.0, 1: 640.0, 2: 1.0, 3: 1.0, 4: 5.0, 5: 1.0, 16: 1.0, 18: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 24: 1.0, 26: 1.0}), age=45, job='blue-collar', marital='married', education='secondary', default='no', balance=640, housing='yes', loan='no', contact='cellular', day=5, month='may', duration=214, campaign=1, pdays=1, previous=1, poutcome='success', y='no', rawPrediction=DenseVector([24.1492, 25.8508]), probability=DenseVector([0.483, 0.517]), prediction=1.0)\n",
      "Row(label=0.0, features=SparseVector(40, {0: 47.0, 1: 668.0, 2: 6.0, 3: 2.0, 4: 4.0, 5: 1.0, 16: 1.0, 18: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 24: 1.0, 26: 1.0}), age=47, job='blue-collar', marital='married', education='secondary', default='no', balance=668, housing='yes', loan='no', contact='cellular', day=4, month='may', duration=230, campaign=6, pdays=354, previous=2, poutcome='success', y='no', rawPrediction=DenseVector([22.173, 27.827]), probability=DenseVector([0.4435, 0.5565]), prediction=1.0)\n",
      "Row(label=0.0, features=SparseVector(40, {0: 27.0, 1: 245.0, 2: 1.0, 3: 2.0, 4: 7.0, 5: 1.0, 16: 1.0, 18: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 24: 1.0, 26: 1.0, 38: 1.0}), age=27, job='blue-collar', marital='married', education='secondary', default='no', balance=245, housing='yes', loan='no', contact='cellular', day=7, month='may', duration=121, campaign=1, pdays=344, previous=2, poutcome='failure', y='no', rawPrediction=DenseVector([46.8357, 3.1643]), probability=DenseVector([0.9367, 0.0633]), prediction=0.0)\n",
      "Row(label=0.0, features=SparseVector(40, {0: 28.0, 1: 373.0, 2: 9.0, 3: 1.0, 4: 14.0, 5: 1.0, 16: 1.0, 18: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 24: 1.0, 26: 1.0, 38: 1.0}), age=28, job='blue-collar', marital='married', education='secondary', default='no', balance=373, housing='yes', loan='no', contact='cellular', day=14, month='may', duration=10, campaign=9, pdays=344, previous=1, poutcome='failure', y='no', rawPrediction=DenseVector([46.8355, 3.1645]), probability=DenseVector([0.9367, 0.0633]), prediction=0.0)\n"
     ]
    }
   ],
   "source": [
    "predictions = rfModel.bestModel.transform(testData)\n",
    "for i in predictions.take(5): print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [[l.getOrDefault(\"inputCol\") + \":\" + x for x in l.labels] \\\n",
    "          for l in pipelineModel.stages if \"StringIndexerModel\" in str(l.__class__)]\n",
    "indexedCols = [j for i in labels for j in i]\n",
    "featureLabels = numCols + indexedCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'balance',\n",
       " 'campaign',\n",
       " 'previous',\n",
       " 'day',\n",
       " 'job:blue-collar',\n",
       " 'job:management',\n",
       " 'job:technician',\n",
       " 'job:admin.',\n",
       " 'job:services',\n",
       " 'job:retired',\n",
       " 'job:self-employed',\n",
       " 'job:entrepreneur',\n",
       " 'job:unemployed',\n",
       " 'job:housemaid',\n",
       " 'job:student',\n",
       " 'job:unknown',\n",
       " 'marital:married',\n",
       " 'marital:single',\n",
       " 'marital:divorced',\n",
       " 'education:secondary',\n",
       " 'education:tertiary',\n",
       " 'education:primary',\n",
       " 'education:unknown',\n",
       " 'default:no',\n",
       " 'default:yes',\n",
       " 'housing:yes',\n",
       " 'housing:no',\n",
       " 'loan:no',\n",
       " 'loan:yes',\n",
       " 'contact:cellular',\n",
       " 'contact:unknown',\n",
       " 'contact:telephone',\n",
       " 'month:may',\n",
       " 'month:jul',\n",
       " 'month:aug',\n",
       " 'month:jun',\n",
       " 'month:nov',\n",
       " 'month:apr',\n",
       " 'month:feb',\n",
       " 'month:jan',\n",
       " 'month:oct',\n",
       " 'month:sep',\n",
       " 'month:mar',\n",
       " 'month:dec',\n",
       " 'poutcome:unknown',\n",
       " 'poutcome:failure',\n",
       " 'poutcome:other',\n",
       " 'poutcome:success',\n",
       " 'y:no',\n",
       " 'y:yes']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 0.1596043421139187),\n",
       " ('education:primary', 0.10761182488758265),\n",
       " ('month:feb', 0.08893854375882428),\n",
       " ('previous', 0.08705721167076327),\n",
       " ('day', 0.07356364438057131),\n",
       " ('balance', 0.07260733159172898),\n",
       " ('month:apr', 0.07176751038225039),\n",
       " ('month:jun', 0.039866004142590034),\n",
       " ('loan:yes', 0.03658198096030473),\n",
       " ('default:yes', 0.02776701799247273),\n",
       " ('month:jul', 0.027247430052649863),\n",
       " ('campaign', 0.024236513148029163),\n",
       " ('month:aug', 0.021093584473934716),\n",
       " ('month:nov', 0.017666950831323643),\n",
       " ('contact:unknown', 0.015534098308977564),\n",
       " ('default:no', 0.012865958963706582),\n",
       " ('loan:no', 0.011524660146354393),\n",
       " ('marital:divorced', 0.00712239086469121),\n",
       " ('job:unknown', 0.006795513448063868),\n",
       " ('housing:no', 0.006670226922586362),\n",
       " ('contact:cellular', 0.00640306858449382),\n",
       " ('education:unknown', 0.00625946450064183),\n",
       " ('job:admin.', 0.005961402148959092),\n",
       " ('month:may', 0.00590543483222255),\n",
       " ('job:technician', 0.0058597337152290555),\n",
       " ('marital:single', 0.005776544215512777),\n",
       " ('marital:married', 0.005529312837122279),\n",
       " ('job:management', 0.0051986795507804945),\n",
       " ('contact:telephone', 0.004694030573768259),\n",
       " ('housing:yes', 0.004050843958682591),\n",
       " ('job:student', 0.003982704714509997),\n",
       " ('education:secondary', 0.003976418430982687),\n",
       " ('job:services', 0.0037139065439773656),\n",
       " ('job:blue-collar', 0.003705442236577154),\n",
       " ('job:self-employed', 0.0032805678379457985),\n",
       " ('job:unemployed', 0.0027842062698800753),\n",
       " ('job:retired', 0.0023510262403640104),\n",
       " ('job:housemaid', 0.002142665097630489),\n",
       " ('job:entrepreneur', 0.0013896948142249714),\n",
       " ('education:tertiary', 0.0009121138551701223)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureImportances = rfModel.bestModel.featureImportances.toArray()\n",
    "featureImportancesMap = zip(featureLabels, featureImportances)\n",
    "sorted(featureImportancesMap, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7724670267807295"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Many Models Orchestration - One Model Per Executor\n",
    "- useful with:\n",
    "    - creating a model grouped by a feature (ex: one model per customer / user)\n",
    "    - creating a model based on a set of hyperparameters for model selecting / tuning\n",
    "    - creating a model based on a set of features for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainXGbModel(partitionKey, labelAndFeatures):\n",
    "    X = np.asarray(list(map(lambda v: v[1].toArray(), labelAndFeatures)))\n",
    "    y = np.asarray(list(map(lambda v: v[0], labelAndFeatures)))\n",
    "    gbClassifier = xgb.XGBClassifier(max_depth=3, seed=123, objective=\"binary:logistic\")\n",
    "    model = gbClassifier.fit(X, y)\n",
    "    return [partitionKey, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbModels = trainData\\\n",
    ".select(\"education\", \"label\", \"features\")\\\n",
    ".repartition(\"education\")\\\n",
    ".rdd\\\n",
    ".map(lambda row: [row[0], [row[1], row[2]]])\\\n",
    ".groupByKey()\\\n",
    ".map(lambda v: trainXGbModel(v[0], list(v[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tertiary',\n",
       "  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "         colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "         max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
       "         n_estimators=100, n_jobs=1, nthread=None,\n",
       "         objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "         reg_lambda=1, scale_pos_weight=1, seed=123, silent=None,\n",
       "         subsample=1, verbosity=1)],\n",
       " ['primary',\n",
       "  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "         colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "         max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
       "         n_estimators=100, n_jobs=1, nthread=None,\n",
       "         objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "         reg_lambda=1, scale_pos_weight=1, seed=123, silent=None,\n",
       "         subsample=1, verbosity=1)],\n",
       " ['unknown',\n",
       "  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "         colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "         max_delta_step=0, max_depth=3, min_child_weight=1, missing=nan,\n",
       "         n_estimators=100, n_jobs=1, nthread=None,\n",
       "         objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "         reg_lambda=1, scale_pos_weight=1, seed=123, silent=None,\n",
       "         subsample=1, verbosity=1)]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbModels.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from spark_sklearn import GridSearchCV\n",
    "\n",
    "parameters = {\"n_estimators\": [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\\\n",
    "             \"max_depth\": [3, 5, 7, 10]}\n",
    "rfSklearn = rf()\n",
    "clf = GridSearchCV(spark.sparkContext, rfSklearn, parameters)\n",
    "model = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _**1 spark job per machine via sklearn to distribute training**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion:   gini\n",
      "max_depth:   3\n",
      "max_features:   auto\n",
      "min_samples_leaf:   1\n",
      "min_samples_split:   2\n",
      "n_estimators:   10\n",
      "n_jobs:   1\n"
     ]
    }
   ],
   "source": [
    "tuning = clf.best_estimator_\n",
    "\n",
    "print(\"criterion:   \" + str(tuning.criterion))\n",
    "print(\"max_depth:   \" + str(tuning.max_depth))\n",
    "print(\"max_features:   \" + str(tuning.max_features))\n",
    "print(\"min_samples_leaf:   \" + str(tuning.min_samples_leaf))\n",
    "print(\"min_samples_split:   \" + str(tuning.min_samples_split))\n",
    "print(\"n_estimators:   \" + str(tuning.n_estimators))\n",
    "print(\"n_jobs:   \" + str(tuning.n_jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0: 87.99\n",
      "#1: 87.86\n",
      "#2: 87.81\n",
      "#3: 87.81\n",
      "#4: 87.85\n",
      "#5: 87.85\n",
      "#6: 87.85\n",
      "#7: 87.84\n",
      "#8: 87.85\n",
      "#9: 87.86\n",
      "#10: 85.63\n",
      "#11: 87.51\n",
      "#12: 87.63\n",
      "#13: 87.54\n",
      "#14: 87.75\n",
      "#15: 87.67\n",
      "#16: 87.48\n",
      "#17: 87.73\n",
      "#18: 86.14\n",
      "#19: 87.07\n",
      "#20: 78.99\n",
      "#21: 80.82\n",
      "#22: 82.86\n",
      "#23: 83.75\n",
      "#24: 84.06\n",
      "#25: 84.45\n",
      "#26: 83.81\n",
      "#27: 84.25\n",
      "#28: 84.85\n",
      "#29: 84.52\n",
      "#30: 70.66\n",
      "#31: 75.70\n",
      "#32: 74.18\n",
      "#33: 74.09\n",
      "#34: 74.58\n",
      "#35: 74.78\n",
      "#36: 74.62\n",
      "#37: 74.15\n",
      "#38: 75.20\n",
      "#39: 74.40\n"
     ]
    }
   ],
   "source": [
    "for i,r in enumerate(clf.cv_results_[\"mean_test_score\"]):\n",
    "    print(\"#{}: {:.2f}\".format(i, r*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Offline Distributed Training - Online Streaming Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, StringIndexerModel, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "stages2 = [] # pipeline stages\n",
    "\n",
    "(trainData2, testData2, holdoutData2) = df.randomSplit([0.7, 0.2, 0.1], seed=123)\n",
    "\n",
    "catCols2 = [\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"month\", \"poutcome\"]\n",
    "for i in catCols2:\n",
    "    si2 = StringIndexer(inputCol=i, outputCol=i+\"Index\") # category indexing\n",
    "    ohe2 = OneHotEncoder(inputCol=i+\"Index\", outputCol=i+\"classVec\") # binary sparse vectors\n",
    "    stages2 += [si2, ohe2]\n",
    "\n",
    "numCols2 = [\"age\", \"balance\", \"campaign\", \"previous\", \"day\"]\n",
    "assemblerInputs2 = numCols2 + list(map(lambda x: x + \"classVec\", catCols2)) # concat cols\n",
    "assembler2 = VectorAssembler(inputCols=assemblerInputs2, outputCol=\"features\")\n",
    "stages2 += [assembler2]\n",
    "\n",
    "labelIndexer2 = StringIndexer(inputCol=\"y\", outputCol=\"label\")\n",
    "stages2 += [labelIndexer2]\n",
    "\n",
    "rf2 = RandomForestClassifier(labelCol=\"label\",\n",
    "                            featuresCol=\"features\",\n",
    "                            maxDepth=10,\n",
    "                            numTrees=20,\n",
    "                            featureSubsetStrategy=\"all\",\n",
    "                            seed=123,\n",
    "                            maxBins=100)\n",
    "stages2 += [rf2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline(stages=stages2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_83c952a59bfc,\n",
       " OneHotEncoder_7c4a637b8526,\n",
       " StringIndexer_c6a550a5e315,\n",
       " OneHotEncoder_875c70daf121,\n",
       " StringIndexer_8886b3a2247f,\n",
       " OneHotEncoder_08daa0dcfb67,\n",
       " StringIndexer_ac3325c715a0,\n",
       " OneHotEncoder_68ec320c3e4e,\n",
       " StringIndexer_d1cb23c608a7,\n",
       " OneHotEncoder_2cb5af6befb7,\n",
       " StringIndexer_732f7676b9a6,\n",
       " OneHotEncoder_f07421b3c235,\n",
       " StringIndexer_fcff48c32fc2,\n",
       " OneHotEncoder_f99a2a2ef3da,\n",
       " StringIndexer_e475c0db0452,\n",
       " OneHotEncoder_b212b8df3860,\n",
       " StringIndexer_3bdaabb9df22,\n",
       " OneHotEncoder_0eb0b0816e98,\n",
       " VectorAssembler_b034a694de88,\n",
       " StringIndexer_949aa4a9075b,\n",
       " RandomForestClassifier_3920a627bef5]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2.getStages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg2 = ParamGridBuilder().addGrid(rf2.numTrees, [30, 40, 50]).build()\n",
    "\n",
    "cv2 = CrossValidator(estimator=pipeline2,\n",
    "                    estimatorParamMaps=pg2,\n",
    "                    numFolds=3,\n",
    "                    seed=123,\n",
    "                    parallelism=4,\n",
    "                    evaluator=BinaryClassificationEvaluator())\n",
    "\n",
    "pipelineModel = cv2.fit(trainData2)\n",
    "\n",
    "testModel = pipelineModel.transform(testData2)\n",
    "\n",
    "testResults = testModel.select(\"features\", \"label\", \"probability\", \"prediction\")\n",
    "\n",
    "bestModel = pipelineModel.bestModel\n",
    "\n",
    "bestModel.write().overwrite().save(\"./pipelineModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "holdoutData2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4487"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdoutData2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdoutData2.drop(\"y\").coalesce(1).write.csv(\"./streamData.csv\", header=\"true\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-5a2348e0-ad49-4ad7-9592-54459d112af8-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./streamData.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "path = \"./pipelineModel\"\n",
    "applyModel = PipelineModel.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_83c952a59bfc,\n",
       " OneHotEncoder_7c4a637b8526,\n",
       " StringIndexer_c6a550a5e315,\n",
       " OneHotEncoder_875c70daf121,\n",
       " StringIndexer_8886b3a2247f,\n",
       " OneHotEncoder_08daa0dcfb67,\n",
       " StringIndexer_ac3325c715a0,\n",
       " OneHotEncoder_68ec320c3e4e,\n",
       " StringIndexer_d1cb23c608a7,\n",
       " OneHotEncoder_2cb5af6befb7,\n",
       " StringIndexer_732f7676b9a6,\n",
       " OneHotEncoder_f07421b3c235,\n",
       " StringIndexer_fcff48c32fc2,\n",
       " OneHotEncoder_f99a2a2ef3da,\n",
       " StringIndexer_e475c0db0452,\n",
       " OneHotEncoder_b212b8df3860,\n",
       " StringIndexer_3bdaabb9df22,\n",
       " OneHotEncoder_0eb0b0816e98,\n",
       " VectorAssembler_b034a694de88,\n",
       " StringIndexer_949aa4a9075b,\n",
       " RandomForestClassificationModel (uid=RandomForestClassifier_3920a627bef5) with 50 trees]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applyModel.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamDF = spark.read.csv(\"./streamData.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = streamDF.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamingData = (spark\n",
    "                 .readStream\n",
    "                 .option(\"header\", \"true\")\n",
    "                 .schema(schema)\n",
    "                 .option(\"maxFilesPerTrigger\", 1)\n",
    "                 .csv(\"./streamData.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (applyModel.transform(streamingData)\n",
    ".writeStream\n",
    ".trigger(processingTime=\"5 seconds\")\n",
    ".queryName(\"preds\")\n",
    ".format(\"memory\")\n",
    ".outputMode(\"append\")\n",
    ".start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4487"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from preds\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- jobIndex: double (nullable = false)\n",
      " |-- jobclassVec: vector (nullable = true)\n",
      " |-- maritalIndex: double (nullable = false)\n",
      " |-- maritalclassVec: vector (nullable = true)\n",
      " |-- educationIndex: double (nullable = false)\n",
      " |-- educationclassVec: vector (nullable = true)\n",
      " |-- defaultIndex: double (nullable = false)\n",
      " |-- defaultclassVec: vector (nullable = true)\n",
      " |-- housingIndex: double (nullable = false)\n",
      " |-- housingclassVec: vector (nullable = true)\n",
      " |-- loanIndex: double (nullable = false)\n",
      " |-- loanclassVec: vector (nullable = true)\n",
      " |-- contactIndex: double (nullable = false)\n",
      " |-- contactclassVec: vector (nullable = true)\n",
      " |-- monthIndex: double (nullable = false)\n",
      " |-- monthclassVec: vector (nullable = true)\n",
      " |-- poutcomeIndex: double (nullable = false)\n",
      " |-- poutcomeclassVec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from preds\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+----------+\n",
      "|probability                              |prediction|\n",
      "+-----------------------------------------+----------+\n",
      "|[0.7902479212093924,0.20975207879060767] |0.0       |\n",
      "|[0.4909773920132184,0.5090226079867816]  |1.0       |\n",
      "|[0.6103170239963902,0.3896829760036098]  |0.0       |\n",
      "|[0.7673288056194824,0.23267119438051762] |0.0       |\n",
      "|[0.5557603280721498,0.4442396719278502]  |0.0       |\n",
      "|[0.457175112600492,0.5428248873995081]   |1.0       |\n",
      "|[0.775905439860338,0.22409456013966195]  |0.0       |\n",
      "|[0.9475619285532805,0.05243807144671945] |0.0       |\n",
      "|[0.9550897521102618,0.044910247889738165]|0.0       |\n",
      "|[0.9550897521102618,0.044910247889738165]|0.0       |\n",
      "|[0.9475624240634223,0.052437575936577836]|0.0       |\n",
      "|[0.9489980875682197,0.051001912431780365]|0.0       |\n",
      "|[0.8884474955517119,0.11155250444828815] |0.0       |\n",
      "|[0.9546531974870512,0.0453468025129487]  |0.0       |\n",
      "|[0.9516945797709683,0.048305420229031705]|0.0       |\n",
      "|[0.7592579153798288,0.2407420846201713]  |0.0       |\n",
      "|[0.6849447649711016,0.3150552350288985]  |0.0       |\n",
      "|[0.835596878309399,0.164403121690601]    |0.0       |\n",
      "|[0.8377032269219741,0.16229677307802592] |0.0       |\n",
      "|[0.9550897521102618,0.044910247889738165]|0.0       |\n",
      "+-----------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select probability, prediction from preds\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
